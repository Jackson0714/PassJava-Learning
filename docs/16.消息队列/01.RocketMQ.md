RocketMQ 架构图

## 整体架构



![](http://cdn.jayh.club/uPic/image-20220208093224992Tvv2Rg.png)

**第一块**就是他的NameServer，这个东西很重要，他要负责去管理集群里所有Broker的信息，让使用MQ的系统可以通过他感知到集群

里有哪些Broker。

**第二块**就是Broker集群本身了，必须得在多台机器上部署这么一个集群，而且还得用主从架构实现数据多副本存储和高可用。

**第三块**就是向MQ发送消息的那些系统了，这些系统一般称之为生产者，这里也有很多细节是值得深究的，因为这些生产者到底是如何

从NameServer拉取路由信息的？如何选择Broker机器建立连接以及发送消息的？

**第四块**就是从MQ获取消息的那些系统，这些系统一般称之为消费者。

### MQ如何集群化部署来支撑高并发访问？

![](http://cdn.jayh.club/uPic/image-20220208093846141QvVQXd.png)

RocketMQ是可以集群化部署的，可以部署在多台机器上，假设每台机器都能抗10万并发，然后你只要让几十万请求分散到多

台机器上就可以了，让每台机器承受的QPS不超过10万不就行了。



### MQ如果要存储海量消息应该怎么做？

其次，每台机器上部署的RocketMQ进程一般称之为Broker，每个Broker都会收到不同的消息，然后就会把这批消息存储在自己本地

的磁盘文件里

这样的话，假设你有1亿条消息，然后有10台机器部署了RocketMQ的Broker，理论上不就可以让每台机器存储1000万条消息了吗？



![image-20220208100456146](http://cdn.jayh.club/uPic/image-20220208100456146GafmV2.png)

所以本质上RocketMQ存储海量消息的机制就是分布式的存储

所谓分布式存储，就是把数据分散在多台机器上来存储，每台机器存储一部分消息，这样多台机器加起来就可以存储海量消息了！

### 高可用保障：万一Broker宕机了怎么办？

RocketMQ的解决思路是Broker主从架构以及多副本策略。

Master Broker收到消息之后会同步给Slave Broker，这样Slave Broker上就能有一模一样的一份副本数据！

候如果任何一个Master Broker出现故障，还有一个Slave Broker上有一份数据副本，可以保证数据不丢失，还能继续对外提供

服务，保证了MQ的可靠性和高可用性。



### 数据路由：怎么知道访问哪个Broker？

怎么知道要连接到哪一台Broker上去发送和接收消息？

有一个NameServer的概念，他也是独立部署在几台机器上的，然后所有的Broker都会把自己注册

到NameServer上去，NameServer不就知道集群里有哪些Broker了？

## NameServer

每个 Broker 启动都得向所有的 NameServer 进行注册

每个 Master Broker得向两台 NameServer 都进行注册的情况。

![](http://cdn.jayh.club/uPic/image-20220208110002299VthLY0.png)

生产者和消费者系统主动去NameServer拉取Broker信息的。

### 如果某个 Broker 宕机了，怎么办？

Broker 和 NameServer 之间有心跳机制，Broker 每隔 30s 给所有的 NameServer 发送心跳，告诉每隔 NameServer 自己目前还活着。

每次NameServer收到一个Broker的心跳，就可以更新一下他的最近一次心跳的时间，然后NameServer会每隔10s运行一个任务，去检查一下各个Broker的最近一次心跳时间，如果某个Broker超过120s都没发送心跳了，那么就认为这个Broker已经挂掉了。

### Broker 宕机，系统是怎么感知到的？

- 跟 Slave 通信？

- 过一会重新从 NameServer 拉取到最新的路由信息，此时就知道有一个 Broker 已经宕机了。

### 其他 MQ 的路由中心

Kafka 的路由中心实际上是一个非常复杂、混乱的存在。他是由ZooKeeper以及某个作为Controller的Broker共同完成的。

RabbitMQ 由集群每个节点同时扮演了路由中心的角色。

RocketMQ是把路由中心抽离出来作为一个独立的NameServer角色运行的，因此可以说在路由中心这块，他的架构设计是最清晰明

了的。

> 问题：如果 NameServer 服务宕机了，RocketMQ 还能正常工作吗？生产者还能发送消息到 Broker 吗？消费者还能从 Broker 拉取消息吗？

## Broker

高可用，将 Broker 部署成 Master-Slave 模式。一对一的。

Master 接收到消息后，将数据同步给 Slave，Master Broker 挂了后，Slave 上有一份数据。

Slave Broker 会向所有的 NameServer 进行注册，也会每 30s 发送一次心跳。

Slave Broker 不停地发送请求到 Master Broker 去拉取消息。Pull 模式。

写入消息：选择 Master Broker 去写入。

读取消息：有可能从Master Broker获取消息，也有可能从Slave Broker获取消息。根据当时Master Broker的负载情况和Slave Broker的同步情况。

### 如果Slave Broke挂掉了有什么影响？

如果Slave Broker挂了，那么此时无论消息写入还是消息拉取，还是可以继续从Master Broke去走，对整体运行不影响，但是会导致所有读写压力都集中在Master Broker上

### 如果Master Broker挂掉了该怎么办？

在RocketMQ 4.5版本之前，都是用Slave Broker同步数据，Master-Slave 模式**不是彻底的高可用模式，他没法实现自动把Slave切换为Master**。需要手动做一些运维操作，把Slave Broker重新修改一些配置，重启机器给调整为Master Broker，这是有点麻烦的，而且会导致中间一段时间不可用。

在RocketMQ 4.5之后，在多个Slave中，通过Dledger技术和Raft协议算法进行leader选举，直接将一个Slave Broker选举为新的Master Broker。

### Broker是如何跟NameServer进行通信的？

TCP长连接：Broker会跟每个NameServer都建立一个TCP长连接，然后定时通过TCP长连接发送心跳请求过去。

各个NameServer就是通过跟Broker建立好的长连接不断收到心跳包，然后定时检查Broker有没有120s都没发送心跳包，来判定集群里各个Broker到底挂掉了没有。

![](http://cdn.jayh.club/uPic/image-20220208200603435cpIAlX.png)

## 如何高可用部署

![](http://cdn.jayh.club/uPic/image-20220208202923578N2azNK.png)

## Topic

Topic 代表数据集合。在发送消息的时候指定你要发送到哪个Topic里面去。

一个订单Topic的数据分布式存储在两个Master Broker上了。

Broker心跳的时候会汇报给NameServer自己的数据情况，这样每个NameServer都知道集群里有哪些Broker，每个Broker存放了哪些Topic的数据。

### 生产者如何发送消息

生产者系统自然就可以通过路由信息找到自己要投递消息的Topic分布在哪几台Broker上，此时可以根据负载均衡算法，从里面选择一台Broke机器出来。选择一台Broker之后，就可以跟那个Broker也建立一个TCP长连接，然后通过长连接向Broker发送消息即可。Broker收到消息之后就会存储在自己本地磁盘里去。

### 消费者如何拉取消息

消费者系统其实跟生产者系统原理是类似的，他们也会跟NameServer建立长连接，然后拉取路由信息，接着找到自己要获取消息的Topic在哪几台Broker上，就可以跟Broker建立长连接，从里面拉取消息了。消费者系统可能会从Master Broker拉取消息，也可能从Slave Broker拉取消息。

这套架构还具备伸缩性，就是说如果要抗更高的并发，存储跟多的数据，完全可以在集群里加入更多的Broker机器，这样就可以线性扩展集群了

## 集群压测

### 监控工具

### RocketMQ 可视化监控工具

git clone https://github.com/apache/rocketmq-externals.git

Zabbix、Open-Falcon、Linux 命令，监控机器的性能和资源使用率

### OS 内核参数调整

（1）vm.overcommit_memory

可选值：0、1、2。

0 表示当系统申请内存时，OS 内核检查可用内存是否足够，如果足够就分配，如果不够就拒绝申请请求，导致申请失败，中间件系统出现异常报错。

1 表示所有可用的物理内存都允许分配。

```
echo 'vm.overcommit_memory=1' >> /etc/sysctl.conf
```

（2）vm.max_map_count

控制中间件系统可以开启的线程的数量。

默认值 65536，建议调大 10 倍

```
echo 'vm.max_map_count=655360' >> /etc/sysctl.conf
```

（3）vm.swappiness

控制进程的swap行为，os会把一部分磁盘空间作为swap区域，然后如果有的进程现在不是太活跃，就会被操作系统把进程调整为睡眠状态，把进程中的数据放入磁盘上的swap区域，然后让这个进程把原来占用的内存空间腾出来，交给其他活跃运行的进程来使用。

如果设置为 0，则表示尽量别把任何一个进程放到磁盘swap区域去，尽量大家都用物理内存。

如果设置为 100，尽量把一些进程给放到磁盘swap区域去，内存腾出来给活跃的进程使用。

默认值 60，偏高，可能导致我们的中间件运行不活跃的时候被迫腾出内存空间然后放到磁盘swap区域去。

建议设置为 10，尽量用物理内存，不要放磁盘 swap 区域。

```
echo 'vm.swappiness=10' >> /etc/sysctl.conf
```

（4）ulimit

网络通信和磁盘文件 IO 跟这个参数相关。

来控制linux上的最大文件链接数。大量频繁的读写磁盘文件的时候，或者是进行网络通信的时候，都会用到这个参数。

默认值 1024，肯定不够，建议设置为 100000。

```
echo 'ulimit -n 1000000' >> /etc/profile
```

### JVM 参数调整

runbroker.sh脚本 中配置了 JVM 启动参数。

-Xms8g -Xmx8g -Xmn4g：默认的堆大小是8g内存，新生代是4g内存，可以根据机器配置进行调整。

### 压测目标

要压测出来一个最合适的最高负载。最主要的是综合TPS以及机器负载，尽量找到一个最高的TPS同时机器的各项负载在可承受范围之内。

到底应该如何压测：应该在TPS和机器的cpu负载、内存使用率、jvm gc频率、磁盘io负载、网络流量负载之间取得一个平衡，尽量让

TPS尽可能的提高，同时让机器的各项资源负载不要太高。

### 压测小结

**到底应该如何压测**：应该在TPS和机器的cpu负载、内存使用率、jvm gc频率、磁盘io负载、网络流量负载之间取得一个平衡，尽量让TPS尽可能的提高，同时让机器的各项资源负载不要太高。

**实际压测过程**：采用几台机器开启大量线程并发读写消息，然后观察TPS、cpu load（使用top命令）、内存使用率（使用free命令）、jvm gc频率（使用jstat命令）、磁盘io负载（使用top命令）、网卡流量负载（使用sar命令），不断增加机器和线程，让TPS不断提升上去，同时观察各项资源负载是否过高。

**生产集群规划**：根据公司的后台整体QPS来定，稍微多冗余部署一些机器即可，实际部署生产环境的集群时，使用高配置物理机，同时合理调整os内核参数、jvm参数、中间件核心参数





## 其他

### 消息队列应用

#### 如何将数据同步给大数据团队？

先是考虑在订单系统代码内部嵌入一些额外的代码，将订单的增删改操作发送到

RocketMQ里，但是后来发现这样会导致污染订单系统的代码。

所以后来我们提出了一个完美的解决方案，就是用Canal、Databus这样的MySQL Binlog同步系统，监听订单数据库的binlog发送到

RocketMQ里

然后大数据团队的数据同步系统从RocketMQ里获取订单数据的增删改binlog日志，还原到自己的数据存储中去，可以是自己的数据

库，或者是Hadoop之类的大数据生态技术。

然后大数据团队将完整的订单数据还原到自己的数据存储中，就可以根据自己的技术能力去出数据报表了，不会再影响订单系统的数据

库了