

# RocketMQ 源码分析

## 95 源码分析的起点：从NameServer的启动脚本开始讲起

你使用mqnamesrv脚本启动NameServer的时候，本质就是基于java命令启动了一个JVM进程，执行NamesrvStartup类中的main()方法，完成NameServer启动的全部流程和逻辑，同时启动NameServer这个JVM进程的时候，有一大堆的默认JVM参数，你当然可以在这里修改这些JVM参数，甚至进行优化。

![](http://cdn.jayh.club/uPic/image-20220221234259529iFVcs0.png)

## 96 NameServer在启动的时候都会解析哪些配置信息？

```java
final NamesrvConfig namesrvConfig = new NamesrvConfig();
final NettyServerConfig nettyServerConfig = new NettyServerConfig();
nettyServerConfig.setListenPort(9876);
```

两个核心配置类在初始化完毕之后，都是交给了NamesrvController

这个核心的组件的。

![](http://cdn.jayh.club/uPic/image-20220221193036592F41Exs.png)

## 97 NameServer是如何初始化基于Netty的网络通信架构的？

这个ServerBootstrap，就是Netty里的一个核心的类，他就是代表了一个Netty网络服务器，通过这个东西，最终可以让Netty监听一个端口号上的网络请求。

![](http://cdn.jayh.club/uPic/image-20220221193528054fRnded.png)

## 98 NameServer最终是如何启动Netty网络通信服务器的？

Netty服务器启动了，开始监听端口号9876了

```java
controller.start();

this.remotingServer.start();



```

绑定端口

ChannelFuture sync = this.serverBootstrap.bind().sync();



![](http://cdn.jayh.club/uPic/image-20220221202428472Py5Fpd.png)

## 99 Broker启动的时候是如何初始化自己的核心配置的？

![](http://cdn.jayh.club/uPic/image-20220221212647582o27Cky.png)

broker在这里启动的时候也是先搞了几个核心的配置组件，包括了broker自己的配置、

broker作为一个netty服务器的配置、broker作为一个netty客户端的配置、broker的消息存储的配置

#### 为什么 Broker 又是 Netty 客户端，又是 Netty 服务器

根 NameServer 建立连接时，broker 作为 Netty 客户端，负责根 NameServer 建立连接和通信

生产者与 Broker 建立连接发送消息时，broker 作为服务器，负责监听客户端的连接请求

#### 配置类

![](http://cdn.jayh.club/uPic/image-20220221212333182vAaRRf.png)

构建配置类、读取配置、文件的配置、解析命令行的配置参数，然后做各种配置的校验和设置。

最终他就会在这里得到4个填充完整的配置类了！

## 100 BrokerController是如何构建出来的，以及他包含了哪些组件？

```java
final BrokerController controller = new BrokerController(
    brokerConfig,
    nettyServerConfig,
    nettyClientConfig,
    messageStoreConfig);
```

![](http://cdn.jayh.club/uPic/image-20220221215410785pLuTuf.png)

Broker这个概念本身代表的不是一个代码组件，他就是你用mqbroker脚本启动的JVM进程。然后JVM进程的main class是BrokerStartup，他是一个启动组件，负责初始化核心配置组件，然后基于核心配置组件去启动BrokerControler这个管控组件。

然后在Broker这个JVM进程运行期间，都是由BrokerController这个管控组件去管理Broker的请求处理、后台线程以及磁盘数据。

## 101 在初始化BrokerController的时候，都干了哪些事情？

了Broker作为一个JVM进程启动之后，是BrokerStartup这个启动组件，负责初始化核心配置组件，然后启动了BrokerController这个管控组件。然后在BrokerController管控组件中，包含了一大堆的核心功能组件和后台线程池组件。

BrokerController一旦初始化完成过后，他其实就准备好了Netty服务器，可以用于接收网络请求，然后准备好了处理各种请求的线程池，准备好了各种执行后台定时调度任务的线程池。

![](http://cdn.jayh.club/uPic/image-20220221234159568dTRnkT.png)

## 102 BrokerContorller在启动的时候，都干了哪些事儿？

```java
controller.start();
```

![](http://cdn.jayh.club/uPic/image-20220221235354849cgWC8z.png)

（1）Broker启动了，必然要去注册自己到NameServer去，所以BrokerOuterAPI这个组件必须要画到自己的图里去，这是一个核心组件

（2）Broker启动之后，必然要有一个网络服务器去接收别人的请求，此时NettyServer这个组件是必须要知道的

（3）当你的NettyServer接收到网络请求之后，需要有线程池来处理，你需要知道这里应该有一个处理各种请求的线程池

（4）你处理请求的线程池在处理每个请求的时候，是不是需要各种核心功能组件的协调？比如写入消息到

commitlog，然后写入索引到indexfile和consumer queue文件里去，此时你是不是需要对应的一些MessageStore之类的组件来配合你？

（5）除此之外，你是不是需要一些后台定时调度运行的线程来工作？比如定时发送心跳到NameServer去，类似这种事情。

##  103 第三个场景驱动：Broker是如何把自己注册到NameServer去的？

Broker注册的时候，最为关键的BrokerOuterAPI这个组件，然后注意到他里面是对每个

NameServer都执行了注册，包括他还构造了RequestHeader和RequestBody组成的请求去进行注册。

![image-20220222095415745](http://cdn.jayh.club/uPic/image-20220222095415745c6mlJa.png)

#### CountDownLatch

![](http://cdn.jayh.club/uPic/image-20220222095856682X99qzB.png)

## 104 深入探索BrokerOuter API是如何发送注册请求的？

Broker注册的时候，在NettyClient底层进行Channel网络连接建立，以及通过Channel

连接把注册请求发送出去的这些逻辑，

![](http://cdn.jayh.club/uPic/image-20220222101002896PYRCKq.png)

## 105 NameServer是如何处理Broker的注册请求的？

NameServer核心其实就是基于Netty服务器来接收Broker注册请求，然后交给DefaultRequestProcessor这个请求处理组件，来处理Broker注册请求。

而真正的Broker注册的逻辑是放在RouteInfoManager这个路由数据管理组件里来进行实现的，最终Broker路由数据都会存放在RouteInfoManager内部的一些Map数据结构组成的路由数据表中。

![](http://cdn.jayh.club/uPic/image-20220222110830289QaxnCa.png)

## 106 Broker是如何发送定时心跳的，以及如何进行故障感知？

![](http://cdn.jayh.club/uPic/image-20220222115505998rT9c3TslJWxf.png)

在BrokerController.start()方法中，在BrokerController启动的时候，他其实并不是仅仅发送一次注册请求，而是启动了一个定时任务，会每隔一段时间就发送一次注册请求。

每隔30s你发送注册请求作为心跳的时候，RouteInfoManager里会进行心跳时间刷新的处理。

![](http://cdn.jayh.club/uPic/image-20220222120311394Tu7Gr5.png)

NamesrvController的initialize()方法里去，里面有一个代码是启动了RouteInfoManager中的一个定时扫描不活跃Broker的线程。

启动一个定时调度线程，每隔10s扫描一次目前不活跃的Broker，使用的是RouteInfoManager中的scanNotActiveBroke()方法

![](http://cdn.jayh.club/uPic/image-20220222120151176gNpXoM.png)

## 107 我们系统中使用的Producer是如何创建出来的？

```java
DefaultMQProducer producer = new DefaultMQProducer("please_rename_unique_group_name");
producer.setNamesrvAddr("127.0.0.1:9876");
producer.start();
```



### 108 构建好的Producer是如何启动准备好相关资源的？

不是核心内容，且源码较为复杂，不用考虑。

### 109 当我们发送消息的时候，是如何从NameServer拉取Topic元数据的？

Topic路由数据拉取，MessageQueue选择，以及跟Broker建立网络连接，通过网络连接发送消息到Broker去，这些逻辑都是在Producer发送消息的时候才会有。

![image-20220222153506925](http://cdn.jayh.club/uPic/image-20220222153506925SP1m2r.png)

封装一个Request请求对象，然后通过底层的Netty客户端发送请求到NameServer，接收到一个Response响应对象。然后他就会从Response响应对象里取出来自己需要的Topic路由数据，更新到自己本地缓存里去，更新的时候会做一些判断，比如Topic路由数据是否有改变过，等等，然后把Topic路由数据放本地缓存就可以了

## 110 对于一条消息，Producer是如何选择MessageQueue去发送的？

```java
MessageQueue mqSelected = this.selectOneMessageQueue(topicPublishInfo, lastBrokerName);
```

在选择Topic中的一个MessageQueue，然后发送消息到这个MessageQueue去，在这行代码里

面，实现了一些Broker故障自动回避机制。

```java
int index = tpInfo.getSendWhichQueue().incrementAndGet();
for (int i = 0; i < tpInfo.getMessageQueueList().size(); i++) {
    int pos = Math.abs(index++) % tpInfo.getMessageQueueList().size();
    if (pos < 0)
        pos = 0;
    MessageQueue mq = tpInfo.getMessageQueueList().get(pos);
    if (latencyFaultTolerance.isAvailable(mq.getBrokerName()))
        return mq;
}
```

上面的代码其实非常的简单，他先获取到了一个自增长的index，大家注意到没有？

接着其实他核心的就是用这个index对Topic的MessageQueue列表进行了取模操作，获取到了一个MessageQueue列表的位置，然后返回了这个位置的MessageQueue。说实话，你只要自己去试试就知道了，这种操作就是一种简单的负载均衡的算法，比如一个Topic有8个MessageQueue，那么可能第一次发送消息到MessageQueue01，第二次就发送消息到MessageQueue02，以此类推，就是轮询把消息发送到各个MessageQueue而已！

![](http://cdn.jayh.club/uPic/image-20220222181641876Vg7idd.png)

## 111 我们的系统与RocketMQ Broker之间是如何进行网络通信的？

在DefaultMQProducerImpl.sendDefaultImpl()方法中，在这个方法里，先是获取到了MessageQueue所在的broker名称，把消息投递到那个Broker上去了。

通过brokerName去本地缓存找他的实际的地址，如果找不到，就去找NameServer拉取Topic的路由数据，然后再次在本地缓存获取broker的实际地址是用自己的方式去封装了一个Request请求出来，这里涉

及到了各种信息的封装，包括了请求头，还有一大堆所有你需要的数据，都封装在Request里了，通过 Netty 发送到指定的 Broker 上。

![](http://cdn.jayh.club/uPic/image-20220222184155906w35gpu.png)

## 112 当Broker获取到一条消息之后，他是如何存储这条消息的？

![](http://cdn.jayh.club/uPic/image-20220222222735208DqGTBp.png)

首先Broker收到一个消息之后，必然是先写入CommitLog文件的

存储目录：${ROCKETMQ_HOME}/store/commitlog

里面会有很多的CommitLog文件，每个文件默认是1GB大小，一个文件写满了就创建一个新的文件，文件名的话，就是文件中的第一个偏移量。

串行写入：

![image-20220222223123536](http://cdn.jayh.club/uPic/image-20220222223123536gJCpDp.png)

接着其实会对消息做出一通处理，包括设置消息的存储时间、创建全局唯一的消息ID、计算消息的总长度，然后会走一段很关键的源码，把消息写入到MappedFile里去，这个其实我们之前还讲解过里面的黑科技，看下面的源码。

实最关键的是cb.doAppend()这行代码，这行代码其实是把消息追加到MappedFile映射的一块内存里去，并没有直接刷入磁盘中。

不管是同步刷盘还是异步刷盘，假设你配置了主从同步，一旦你写入完消息到CommitLog之后，接下来都会进行主从同步复制的。

## 113 一条消息写入CommitLog文件之后，如何实时更新索引文件？

![image-20220222224424853](http://cdn.jayh.club/uPic/image-20220222224424853lrodnd.png)

Broker启动的时候会开启一个线程，ReputMessageService

在这个线程里，每隔1毫秒，就会把最近写入CommitLog的消息进行一次转发，转发到ConsumeQueue和IndexFile里去，通过的是doReput()方法来实现的。

调用doDispatch()方法去把消息进行转发，一个是转发到ConsumeQueue里去，一个是转发到IndexFile里去。

找到当前Topic的messageQueueId对应的一个ConsumeQueue文件，写入消息到这个文件。

##  114 RocketMQ是如何实现同步刷盘以及异步刷盘两种策略的？

### 同步刷盘

构建 GroupCommitRequest，交给 GroupCommitService处理。调用 request.waitForFlush() 方法等待同步刷盘成功。

MappedByteBuffer.force()方法执行刷盘，它是 JDK NIO 包的 API。

如果刷盘失败，则打印日志。

### 异步刷盘

唤醒了一个 flushCommitLogService 组件。子类是 CommitRealTimeService，唤醒的是它的子类线程。

run 方法有定时刷新的逻辑。每隔一定时间进行刷盘，最大间隔 10s。

##  115 当Broker上的数据存储超过一定时间之后，磁盘数据是如何清理的？

每隔 10s，执行一个调度任务，执行 DefaultMessageStore.this.cleanFilesPeriodically()方法。

如果当前时间是预设的凌晨 4 点，或磁盘空间使用率超过 85%，则触发删除磁盘文件。

如果磁盘空间超过 90%，则不允许写入消息到文件中，直接删除磁盘文件。

删除哪些文件呢？检查 CommitLog 文件、ConsumeQueue 文件，是否超过 72 小时未修改过，如果是的，则执行删除操作。可以通过这个配置 fileReservedTime 参数来设置要保留文件的时长。

如果有的消息还没有消费过，也会被删除。

![](http://cdn.jayh.club/uPic/image-20220223103526029rAcUsh.png)

## 116 我们系统中的Consumer作为消费者是如何创建出来的？

首先Consumer刚启动，必须依托Rebalancer组件，去进行一下重平衡，自己要分配一些MessageQueue去拉取消息。接着拉取消息，必须要依托PullAPI组件通过底层网络通信去拉取。在拉取的过程中，必然要维护offset消费进度，此时就需要OffsetStore组件。万一要是ConsumerGroup里多了Consumer或者少了Consumer，又要依托Rebalancer组件进行重平衡了。

![](http://cdn.jayh.club/uPic/image-20220223152257024LP2GP5.png)

## 117 一个消费组中的多个Consumer是如何均匀分配消息队列的？

> 一个业务系统部署在两台机器上，对应一个消费组里就有两个Consumer，那么现在一个Topic有三个MessageQueue，该怎么分配呢？

![](http://cdn.jayh.club/uPic/image-2022022316265526765uG3h.png)

consumer 启动后，会向所有 broker 进行注册，并且持续保持自己的心跳.每个broker 都感知到 消费者组里面有哪些 consumer。

![](http://cdn.jayh.club/uPic/image-20220223162818320TmigJu.png)

重平衡组件随机挑选一个 broker，获取这个消费者里面有哪些 consumer 存在。把 Topic 下 MessageQueue 均匀分配给 Consumer。

一旦 MessageQueue 负载确定后，Consumer 就知道消费哪几个 MessageQueue，然后连接到它的 broker 上，就可以不断拉取消息进行消费了。