

## 数据库瓶颈

不管是 IO 瓶颈，还是 CPU 瓶颈，最终都会导致数据库的活跃连接数增加，进而逼近甚至达到数据库可承载活跃连接数的阈值。

在业务 Service 来看就是，可用数据库连接少甚至无连接可用。接下来就可以想象了吧（并发量、吞吐量、崩溃）。

### 1、IO 瓶颈

第一种：磁盘读 IO 瓶颈，热点数据太多，数据库缓存放不下，每次查询时会产生大量的 IO，降低查询速度 -> 分库和垂直分表。

第二种：网络 IO 瓶颈，请求的数据太多，网络带宽不够 -> 分库。

### 2、CPU 瓶颈

第一种：SQL 问题，如 SQL 中包含 join，group by，order by，非索引字段条件查询等，增加 CPU 运算的操作 -> SQL 优化，建立合适的索引，在业务 Service 层进行业务计算。

第二种：单表数据量太大，查询时扫描的行太多，SQL 效率低，CPU 率先出现瓶颈 -> 水平分表。

## 分库分表

### 1、水平分库

![img](http://cdn.jayh.club/uPic/640rtD1DW.png)

概念：以字段为依据，按照一定策略（hash、range 等），将一个库中的数据拆分到多个库中。

结果：

- 每个库的结构都一样；
- 每个库的数据都不一样，没有交集；
- 所有库的并集是全量数据；

场景：系统绝对并发量上来了，分表难以根本上解决问题，并且还没有明显的业务归属来垂直分库。

分析：库多了，io 和 cpu 的压力自然可以成倍缓解。

### 2、水平分表

![img](http://cdn.jayh.club/uPic/640-20220406091857867elsNTZ.png)

概念：以字段为依据，按照一定策略（hash、range 等），将一个表中的数据拆分到多个表中。

结果：

- 每个表的结构都一样；
- 每个表的数据都不一样，没有交集；
- 所有表的并集是全量数据；

场景：系统绝对并发量并没有上来，只是单表的数据量太多，影响了 SQL 效率，加重了 CPU 负担，以至于成为瓶颈。

分析：表的数据量少了，单次 SQL 执行效率高，自然减轻了 CPU 的负担。

### 3、垂直分库

![img](http://cdn.jayh.club/uPic/640-20220406091857898J0a4Fo.png)

概念：以表为依据，按照业务归属不同，将不同的表拆分到不同的库中。

结果：

- 每个库的结构都不一样；
- 每个库的数据也不一样，没有交集；
- 所有库的并集是全量数据；

场景：系统绝对并发量上来了，并且可以抽象出单独的业务模块。

分析：到这一步，基本上就可以服务化了。例如，随着业务的发展一些公用的配置表、字典表等越来越多，这时可以将这些表拆到单独的库中，甚至可以服务化。再有，随着业务的发展孵化出了一套业务模式，这时可以将相关的表拆到单独的库中，甚至可以服务化。

### 4、垂直分表

![img](http://cdn.jayh.club/uPic/640-20220406091857930gulQUH.png)

概念：以字段为依据，按照字段的活跃性，将表中字段拆到不同的表（主表和扩展表）中。

结果：

- 每个表的结构都不一样；
- 每个表的数据也不一样，一般来说，每个表的字段至少有一列交集，一般是主键，用于关联数据；
- 所有表的并集是全量数据；

场景：系统绝对并发量并没有上来，表的记录并不多，但是字段多，并且热点数据和非热点数据在一起，单行数据所需的存储空间较大。以至于数据库缓存的数据行减少，查询时会去读磁盘数据产生大量的随机读 IO，产生 IO 瓶颈。

分析：可以用列表页和详情页来帮助理解。垂直分表的拆分原则是将热点数据（可能会冗余经常一起查询的数据）放在一起作为主表，非热点数据放在一起作为扩展表。这样更多的热点数据就能被缓存下来，进而减少了随机读 IO。拆了之后，要想获得全部数据就需要关联两个表来取数据。

但记住，千万别用 join，因为 join 不仅会增加 CPU 负担并且会讲两个表耦合在一起（必须在一个数据库实例上）。关联数据，应该在业务 Service 层做文章，分别获取主表和扩展表数据然后用关联字段关联得到全部数据。

## 分库分表工具

- sharding-sphere：jar，前身是 sharding-jdbc；
- TDDL：jar，Taobao Distribute Data Layer；
- Mycat：中间件。

“

注：工具的利弊，请自行调研，官网和社区优先。

”

## 分库分表步骤

根据容量（当前容量和增长量）评估分库或分表个数 -> 选 key（均匀）-> 分表规则（hash 或 range 等）-> 执行（一般双写）-> 扩容问题（尽量减少数据的移动）。

## 分库分表问题

### 1、非 partition key 的查询问题

基于水平分库分表，拆分策略为常用的 hash 法。

端上除了 partition key 只有一个非 partition key 作为条件查询

映射法

![img](http://cdn.jayh.club/uPic/640-20220406091857962C5XpNS.png)

基因法

![img](http://cdn.jayh.club/uPic/640-202204060918579934OD53z.png)

“

注：写入时，基因法生成 user_id，如图。关于 xbit 基因，例如要分 8 张表，23=8，故 x 取 3，即 3bit 基因。根据 user_id 查询时可直接取模路由到对应的分库或分表。

根据 user_name 查询时，先通过 user_name_code 生成函数生成 user_name_code 再对其取模路由到对应的分库或分表。id 生成常用 snowflake 算法。

”

端上除了 partition key 不止一个非 partition key 作为条件查询

映射法

![img](http://cdn.jayh.club/uPic/640-20220406091858023CCYn08.png)

冗余法

![img](http://cdn.jayh.club/uPic/640-20220406091858056VvO6eq.png)

“

注：按照 order_id 或 buyer_id 查询时路由到 db_o_buyer 库中，按照 seller_id 查询时路由到 db_o_seller 库中。感觉有点本末倒置！有其他好的办法吗？改变技术栈呢？

”

后台除了 partition key 还有各种非 partition key 组合条件查询

NoSQL 法

![img](http://cdn.jayh.club/uPic/640-20220406091858088aydHum.png)

冗余法

![img](http://cdn.jayh.club/uPic/640-2022040609185811732RAzN.png)

### 2、非 partition key 跨库跨表分页查询问题

基于水平分库分表，拆分策略为常用的 hash 法。

“

注：用 NoSQL 法解决（ES 等）。

”

### 3、扩容问题

基于水平分库分表，拆分策略为常用的 hash 法。

水平扩容库（升级从库法）



![img](http://cdn.jayh.club/uPic/640eDbhzr.jpeg)



“

注：扩容是成倍的。

”

水平扩容表（双写迁移法）



![img](http://cdn.jayh.club/uPic/640-20220406091858199GmX009.png)



- 第一步：（同步双写）修改应用配置和代码，加上双写，部署；
- 第二步：（同步双写）将老库中的老数据复制到新库中；
- 第三步：（同步双写）以老库为准校对新库中的老数据；
- 第四步：（同步双写）修改应用配置和代码，去掉双写，部署；

“

注：双写是通用方案。

”

## 分库分表总结

- 分库分表，首先得知道瓶颈在哪里，然后才能合理地拆分（分库还是分表？水平还是垂直？分几个？）。且不可为了分库分表而拆分。
- 选 key 很重要，既要考虑到拆分均匀，也要考虑到非 partition key 的查询。
- 只要能满足需求，拆分规则越简单越好。