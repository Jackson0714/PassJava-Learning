# Logstash 不完全填坑指南

你好，我是悟空呀，赛亚人又和小伙伴们见面了~

本篇内容主要如下：

> 思维导图

在使用 Logstash 遇到的坑，本篇也会讲解解决方案。

- 日志记录的格式复杂，正则表达式非常磨人。
- 服务日志有多种格式，如何匹配。
- 错误日志打印了堆栈信息，包含很多行，如何合并。
- 日志记录行数过多（100多行），被拆分到了其他记录中。
- 输出到 ES 的日志包含很多无意义字段。
- 输出到 ES 的日志时间和本来的日志时间相差 8 小时。
- 服务器（ubuntu 18.04 系统）开机后，如何自动重启 logstash。

## 一、部署架构图

上次我们聊到了 ELK Stack 的搭建：

[一文带你搭建一套 ELK Stack 日志平台](http://mp.weixin.qq.com/s?__biz=MzAwMjI0ODk0NA==&mid=2451962693&idx=1&sn=96530613aaadd8240d8a5c2ab7dff49d&chksm=8d1c02daba6b8bcc2499861fd37aac5cfa88d616fc839cb6a7a3c003118457ac325c3dcbeb62#rd)

最近悟空正在我们的测试环境部署这一套 ELK，发现还是有很多内容需要再单独拎几篇出来详细讲讲的，这次我会带着大家一起来看下 ELK 中的 Logstash 组件的落地玩法和踩坑之路。

测试环境目前有 **12** 台机器，其中 有 **4** 台给后端微服务、Filebeat、Logstash 使用，**3** 台给 ES 集群 和 Kibana 使用。

部署拓扑图如下：

![](http://cdn.jayh.club/uPic/image-20220531213505055GrA0Ti.png)

**部署说明**：

- 4 台服务器给业务微服务服务使用，微服务的日志会存放本机上。

- 4 台服务器都安装 Filebeat 日志采集器，采集本机的微服务日志，

- 其中一台服务器安装 Logstash ，Filebeat 发送日志给 Logstash。Logstash 将日志输出到 Elasticsearch 集群中。
- 3 台服务器都安装有 Elasticsearch 服务，组成 ES 集群。其中一台安装 Kibana 服务，查询 ES 集群中的日志信息。

## 二、Logstash 用来做什么？

你是否还在苦恼每次生产环境出现问题都需要远程到服务器查看日志文件？

你是否还在没有统一的日志搜索入口而烦心？

你是否还在为从几十万条日志中搜索关键信息而苦恼？

没错，Logstash 它来啦，带着所有的日志记录来啦。

Logstash 它是帮助我们收集、解析和转换日志的。作为 ELK 中的一员，发挥着很大的作用。

当然 Logstash 不仅仅用在收集日志方面，还可以收集其他内容，我们最熟悉的还是用在日志方面。

## 三、Logstash 的原理

### 3.1 从 Logstash 自带的配置说起

Logstash 的原理其实还比较简单，一个输入，一个输出，中间有个管道（不是必须的），这个管道用来收集、解析和转换日志的。如下图所示：

![Logstash 组件](http://cdn.jayh.club/uPic/image-20220531214759946KrvhKq.png)

Logstash 运行时，会读取 Logstash 的配置文件，配置文件可以配置输入源、输出源、以及如何解析和转换的。

Logstash 配置项中有两个必需元素，输入（inputs）和输出（ouputs），以及一个可选元素 filters 过滤器插件。 input 可以配置来源数据，过滤器插件在你指定时修改数据，output 将数据写入目标。

我们来看下 Logstash 软件自带的一个示例配置，文件路径：\logstash-7.6.2\config\logstash-sample.conf

![](http://cdn.jayh.club/uPic/image-202205312051424701hBVzu.png)

是不是很简单，一个 input 和 一个 output 就搞定了。如下图所示：

![](http://cdn.jayh.club/uPic/image-20220531215359297n9Z89F.png)

但是这种配置其实意义不大，没有对日志进行解析，传到 ES 中的数据是原始数据，也就是一个 message 字段包含一整条日志信息，不便于根据字段搜索。

### 3.2 Input 插件

配置文件中 input 输入源指定了 beats，而 beats 是一个大家族，Filebeat 只是其中之一。对应的端口 port = 5044，表示 beats 插件可以往 5044 端口发送日志，logstash 可以接收到通过这个端口和 beats 插件通信。

在部署架构图中，input 输入源是 Filebeat，它专门监控日志的变化，然后将日志传给 Logstash。在早期，Logstash 是自己来采集的日志文件的。所以早期的日志检索方案才叫做 ELK，Elasticsearch + Logstash + Kibana，而现在加入了 Filebeat 后，这套日志检索方案属于 ELK Stack，不是 ELKF，摒弃了用首字母缩写来命名。

另外 input 其实有很多组件可以作为输入源，不限于 Filebeat，比如我们可以用 Kafka 作为输入源，将消息传给 Logstash。具体有哪些插件列表，可以看这个 [^input 插件列表]

### 3.3 Filter 插件

而对于 Logstash 的 Filter，这个才是 Logstash 最强大的地方。Filter 插件也非常多，我们常用到的 grok、date、mutate、mutiline 四个插件。

#### 3.2.1 日志示例

我以我们后端服务打印的日志为例，看是如何用 filter 插件来解析和转换日志的。

logback.xml 配置的日志格式如下：

``` SH
<encoder>
    <pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger - %msg%n</pattern>
</encoder>
```

日志格式解释如下：

- 记录日志时间：%d{yyyy-MM-dd HH:mm:ss.SSS}

- 记录是哪个线程打印的日志：[%thread]

- 记录日志等级：%-5level
- 打印日志的类：%logger
- 记录具体日志信息：%msg%n，这个 msg 的内容就是 log.info("abc") 中的 abc。

通过执行代码 log.info("xxx") 后，就会在本地的日志文件中追加一条日志。

#### 3.2.2 打印的日志内容

从服务器拷贝出了一条日志，看下长什么样，有部分敏感信息我已经去掉了。

``` SH
2022-06-16 15:50:00.070 [XNIO-1 task-1] INFO  com.passjava.config - 方法名为:MemberController-,请求参数:{省略}
```

那么 Logstash 如何针对上面的信息解析出对应的字段呢？比如如何解析出打印日志的时间、日志等级、日志信息？

#### 3.2.3 grok 插件

这里就要用到 logstash 的 filter 中的 grok 插件。filebeat 发送给 logstash 的日志内容会放到message 字段里面，logstash 匹配这个 message 字段就可以了。配置项如下所示：

``` json
filter {
	grok {
      match => [ "message", "(?<logTime>\d{4}-\d{2}-\d{2}\s\d{2}:\d{2}:\d{2}.\d{3})\s+\[(?<thread>.*)\]\s+(?<level>\w*)\s{1,2}+(?<class>\S*)\s+-\s+(?<content>.*)\s*"]
  }
}
```

转换后的日志如下：



**比较坑的是**我们后端项目的不同服务打印了两种不同格式的日志，那这种如何匹配？

再加一个 match 就可以了。

``` JSON
filter {
	grok {
      match => [ "message", "(?<logTime>\d{4}-\d{2}-\d{2}\s\d{2}:\d{2}:\d{2}.\d{3})\s+\[(?<thread>.*)\]\s+(?<level>\w*)\s{1,2}+(?<class>\S*)\s+-\s+(?<content>.*)\s*"]
      match => [ "message", "(?<logTime>\d{4}-\d{2}-\d{2}\s\d{2}:\d{2}:\d{2}.\d{3})\s{1,2}+(?<level>\w*)\s{1,2}+.\s---+\s\[(?<thread>.*)\]+\s(?<class>\S*)\s*:+\s(?<content>.*)\s*"]
  }
}
```

当任意一个 message 匹配上了这个正则，则 grok 执行完毕。假如还有第三种格式的 message，那么虽然 grok 没有匹配上，但是 message 也会输出到 ES，只是这条日志在 ES 中不会展示 logTime、level 等字段。

#### 3.2.4 multiline 插件

**还有一个坑的地方**是错误日志一般都是很多行的，会把堆栈信息打印出来，当经过 logstash 解析后，每一行都会当做一条记录存放到 ES，那这种情况肯定是需要处理的。这里就需要使用 multiline 插件，对属于同一个条日志的记录进行拼接。

multiline 不是 logstash 自带的，需要单独进行安装。我们的环境是没有外网的，所以需要进行离线安装。

介绍在线和离线安装 multiline 的方式：

- 在线安装插件。

在 logstash 根目录执行以下命令进行安装。

```python
bin/logstash-plugin install logstash-filter-multiline
```

![](http://cdn.jayh.club/uPic/image-202204291706593160mbyPF.png)

- 离线安装插件。

在有网的机器上在线安装插件，然后打包。

``` SH
bin/logstash-plugin install logstash-filter-multiline
bin/logstash-plugin prepare-offline-pack logstash-filter-multiline
```

拷贝到服务器，执行安装命令。安装插件需要等待 5 分钟左右的时间，控制台界面会被 hang 住，当出现 Install successful 表示安装成功。

``` SH
bin/logstash-plugin install file:///home/software/logstash-offline-plugins-7.6.2.zip
```

![](http://cdn.jayh.club/uPic/image-202205051147198464Ojg5a.png)

检查下插件是否安装成功，可以执行以下命令查看插件列表。

```python
bin/logstash-plugin list
```













logstash 配置文件内容如下：

``` JSON
input {
  beats {
    port => 9900
  }
}

filter {

  multiline {
    pattern => "^\d{4}-\d{1,2}-\d{1,2}\s\d{1,2}:\d{1,2}:\d{1,2}.\d{3}"
    negate => true
    what => "previous"
  }

  grok {
      match => [ "message", "(?<logTime>\d{4}-\d{2}-\d{2}\s\d{2}:\d{2}:\d{2}.\d{3})\s+\[(?<thread>.*)\]\s+(?<level>\w*)\s{1,2}+(?<class>\S*)\s+-\s+(?<content>.*)\s*"]
      match => [ "message", "(?<logTime>\d{4}-\d{2}-\d{2}\s\d{2}:\d{2}:\d{2}.\d{3})\s{1,2}+(?<level>\w*)\s{1,2}+.\s---+\s\[(?<thread>.*)\]+\s(?<class>\S*)\s*:+\s(?<content>.*)\s*"]
      match => [
           "source", "/home/tss/logs/(?<logName>\w+)/.*.log"
       ]
      overwrite => [ "source"]
      break_on_match => false
  }

  mutate {
    convert => {
      "bytes" => "integer"
    }
    remove_field => ["agent","message","@version", "tags", "ecs", "_score", "input", "[log][offset]"]
  }

  useragent {
    source => "user_agent"
    target => "useragent"
  }

  date {
    match => ["logTime", "MMM d HH:mm:ss", "MMM dd HH:mm:ss", "ISO8601"]
    timezone => "Asia/Shanghai"
  }
}

output {
  stdout { }

  elasticsearch {
    hosts => ["10.27.119.64:9200","10.27.119.65:9200","10.27.119.66:9200"]
    index => "qa_log"
  }
}
```









我们首先需要创建一个配置文件，配置内容如下图所示：

![](http://cdn.jayh.club/uPic/image-20220428162630243dSLSIZ.png)







## Logstash 怎么跑起来的

Logstash 其实是一个 Java 应用程序，我们用 java 命令就可以启动 logstash 程序。

我们一般不会自己去用 java 命令来启动 logstash，我们只需要按照 Logstash 官方告诉我们的启动方式就可以了，比如：

```SH
cd /home/logstash-7.6.2/bin/

logstash -f weblog.conf
```

那么这个 









![image-20220527171319854](D:/_workspace/wh-docs/images/image-20220527171319854.png)









注意这里的 index 名称必须是小写，不然写入 es 时会报错。

![](http://cdn.jayh.club/uPic/image-20220526152819384jQiYhz.png)

到 ES 中查询的时间多了一个字母 Z，代表 UTC时间，也就是说 ES 中存的时间比日志记录的时间晚 8 个小时。

![](http://cdn.jayh.club/uPic/image-20220526152551675v7KqJ2.png)

增加配置  timezone => "Asia/Shanghai"

``` SH
date {
    match => ["logTime", "MMM d HH:mm:ss", "MMM dd HH:mm:ss", "ISO8601"]
    timezone => "Asia/Shanghai"
  }
```

然后加一条日志后查看结果，Kibana 显示 @timestamp 字段和日志的记录时间一致了。

![](http://cdn.jayh.club/uPic/image-20220526153228992e1dX0T.png)







正则表达式参考资料：https://www.runoob.com/regexp/regexp-syntax.html

安装插件

- 在线安装插件

```python
bin/logstash-plugin install logstash-filter-multiline
```

![](http://cdn.jayh.club/uPic/image-20220429170659316ZmZlap.png)

- 离线安装插件

https://blog.51cto.com/u_15499621/5065154

在有网的机器上在线安装插件，然后打包。安装插件需要 5 分钟

``` SH
bin/logstash-plugin install logstash-filter-multiline
bin/logstash-plugin prepare-offline-pack logstash-filter-multiline
```

拷贝到服务器，执行安装命令

``` SH
bin/logstash-plugin install file:///home/software/logstash-offline-plugins-7.6.2.zip
```

![](http://cdn.jayh.club/uPic/image-20220505114719846KVD0G7.png)

查看插件列表

```python
bin/logstash-plugin list
```



## 五、添加到开机启动项中

建立rc-local.service文件

``` SH
sudo vim /etc/systemd/system/rc-local.service
```

将下列内容复制进 rc-local.service 文件

``` SH
[Unit]
Description=/etc/rc.local Compatibility
ConditionPathExists=/etc/rc.local
 
[Service]
Type=forking
ExecStart=/etc/rc.local start
TimeoutSec=0
StandardOutput=tty
RemainAfterExit=yes
SysVStartPriority=99
 
[Install]
WantedBy=multi-user.target
```

创建文件 rc.local

``` SH
sudo vim /etc/rc.local
```

添加启动脚本到启动文件中

``` SH
#!/bin/sh -e
#
# rc.local
#
# This script is executed at the end of each multiuser runlevel.
# Make sure that the script will "exit 0" on success or any other
# value on error.
#
# In order to enable or disable this script just change the execution
# bits.
#
# By default this script does nothing.

# 启动 logstash
#nohup /home/software/logstash-7.6.2/bin/logstash -f /home/software/logstash-7.6.2/weblog.conf &

# 启动 filebeat
nohup /home/software/filebeat-7.6.2-linux-x86_64/filebeat -e -c /home/software/filebeat-7.6.2-linux-x86_64/config.yml &

exit 0
```

因在开机启动中，logstash 找不到 java 的运行环境，所以需要手动配置下 logstash。

``` SH
cd /home/software/logstash-7.6.2/bin/
sudo vim logstash.lib.sh

```

在 setup_java() 方法的第一行加入 JAVA_HOME 变量，JAVA_HOME 的路径需要根据自己的 java 安装目录来。

``` SH
JAVA_HOME="/opt/java/jdk1.8.0_181"
```

![](D:/_workspace/wh-docs/images/image-20220527134749917.png)





给 rc.local 加上权限,启用服务

``` SH
sudo chmod +x /etc/rc.local
sudo systemctl enable rc-local
sudo systemctl stop rc-local.service
sudo systemctl start rc-local.service
sudo systemctl status rc-local.service
```

权限问题的解决方案 https://www.elastic.co/guide/en/beats/libbeat/current/config-file-permissions.html





启动 Logstash

```sh
nohup bin/logstash -f weblog.conf &
# 查看logstash进程是否开启
ps -ef | grep logstash
```

再运行 Filebeat， -c 表示运行指定的配置文件，这里是 config.yml。

```SH
#控制台方式启动
/home/software/logstash-7.6.2/bin/logstash -f /home/software/logstash-7.6.2/weblog.conf &

#守护进程方式启动
nohup /home/software/filebeat-7.6.2-linux-x86_64/filebeat -e -c /home/software/filebeat-7.6.2-linux-x86_64/config.yml &
```

## 





[^input 插件列表]: https://www.elastic.co/guide/en/logstash/current/input-plugins.html
