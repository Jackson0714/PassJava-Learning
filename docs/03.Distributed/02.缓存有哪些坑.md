# 三、分布式缓存的坑

## 1. 缓存的坑之缓存雪崩

在高频访问数据库的场景中，我们会在业务层和数据层之间加入一套缓存机制，来分担数据库的访问压力，毕竟访问磁盘 I/O 的速度是很慢的。比如利用缓存来查数据，可能5ms就能搞定，而去查数据库可能需要 50 ms，差了一个数量级。而在高并发的情况下，数据库还有可能对数据进行加锁，导致访问数据库的速度更慢。

分布式缓存我们用的最多的就是 Redis了，它可以实现分布式

![缓存挂了](http://cdn.jayh.club/blog/20200921/152903037.png)

> `坑：` 
>
> - 缓存每秒最高访问量 8000次/s。高峰期每秒访问缓存 10000 次，导致缓存异常宕机。
>
> - 10000次请求全部都走数据库，数据库肯定悲剧，数据库服务的 CPU 使用率 100 %。系统不可用。
> - 运维把数据库服务重启后，因访问量还是走数据库，数据库服务的 CPU 又到 100 % 了。
> - 怎么理解雪崩：因 DB CPU 100%，其他访问数据库的操作全部都超时了，因缓存的问题，带来了数据库层面更大的问题，而导致越来越来的服务不可用，这就是雪崩了，问题来得快来得猛。

**解决思路：**

- 缓存宕机后，必须能快速恢复缓存服务。
- 对访问数据库进行限流，避免数据库挂了。
- 缓存必须保证高可用，即使一个节点挂了，还有其他节点提供服务，如果是不可抗力因素导致全部节点挂了，那就只能按照快速恢复方案来实施了。

解决方案：

- 

## 9. 缓存的坑之缓存穿透



## 10.缓存的坑之缓存击穿